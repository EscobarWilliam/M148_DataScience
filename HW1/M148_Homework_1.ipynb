{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EscobarWilliam/M148_DataScience/blob/main/M148_Homework_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6Elc_p5OpvO"
      },
      "source": [
        "# CS M148 Homework Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "612688cNOpvQ"
      },
      "source": [
        "I certify that I have completed all parts of this assignment on my own. **[TODO: Fill your name and UID here.]**\n",
        "- Name:\n",
        "- UID:\n",
        "\n",
        "Due date: Wednesday, July 3 at 11:59 PM PDT\n",
        "\n",
        "Instruction: You may form small groups (e.g. of up to four people) to work on this assignment, but you must write up all solutions by yourself. The Homework needs to be submitted on BruinLearn and please refer to the late submission policy in Lecture one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAmbIeJPOpvR"
      },
      "source": [
        "## 1. Polling Data Collection and Analysis (8 pts)\n",
        "Your friend working at the Los Angeles Mayor's office has been given the task of determining how voters feel about the mayor's performance, and his chances of winning reelection. Your friend wants to accomplish this by conducting a voluntary poll, and has decided to advertise the poll on certain popular social media sites in order to get a large response. Using the responses, he wants to train a predictive model to anticipate the likely election outcome based on both the sentiment and intensity of responses received. What are some of the issues, if any, with what your friend proposes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSCn86jhOpvR"
      },
      "source": [
        "**[TODO: Fill your response here]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij6OSAUEOpvS"
      },
      "source": [
        "## 2. Utility of One-Hot-Encoding (15 pts, 3 pts each)\n",
        "One-Hot-Encoding is a process of converting a single categorical variable (with multiple discrete options) into a number of binary features, one for each possible value. This is often an incredibly important data pre-processing step; however, there are times when it is inappropriate to employ one-hot-encoding. Please evaluate the following features and determine if you would one-hot-encode them. Justify your response:\n",
        "- (a) Zipcode\n",
        "- (b) Income Level\n",
        "- (c) Age\n",
        "- (d) Cuisine Category\n",
        "- (e) All the states in the U.S."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmMsTdofOpvS"
      },
      "source": [
        "**[TODO: Fill your response here]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQEZpFC9OpvS"
      },
      "source": [
        "## 3. True or False, Simple Explanations (15 pts, 3 pts each)\n",
        "Provide brief explanations for your answers.\n",
        "- (a) (T or F) Categorical Variables can be used only when the number of categories is finite.\n",
        "- (b) (T or F) Correlation refers to the linear dependence between two variables.\n",
        "- (c) (T or F) Supervised Learning and Unsupervised learning differ in that Supervised Learning require labels whereas Unsupervised Learning doesn't.\n",
        "- (d) (T or F) Median is usually preferred over mean as a summary statistics when there are extreme values.\n",
        "- (e) (T or F) Sample variance is an unbiased estimator for the population variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbykV1DhOpvS"
      },
      "source": [
        "**[TODO: Fill your response here]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFqwT49qOpvT"
      },
      "source": [
        "## 4. Data Preprocessing (12 pts, 3 pts each)\n",
        "- (a) Explain why normalization and standardization are used in data preprocessing steps.\n",
        "- (b) List at least 2 ways to normalize the dataset.\n",
        "- (c) Illustrate 2 ways to deal with a dataset with missing values and explain the reason behind each approach.\n",
        "- (d) Suppose you have a table with 4 columns. 3 of the 4 columns are numerical values, and the rest is a column with categorical values. Suppose that we want to predict a numeric column and treat the rest as features. What is the type of machine learning task in this case? In order to perform this machine learning task, What are the preprocessing steps we may want to take for the features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS-xZODAOpvT"
      },
      "source": [
        "**[TODO: Fill your response here]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPa6I-XrOpvT"
      },
      "source": [
        "## 5. Linear Regression Analysis (35 pts, 5 pts each)\n",
        "\n",
        "### Code completion\n",
        "\n",
        "Use the dataset provided below and perform a linear regression analysis. Follow the steps outlined to complete the exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvQGInKbOpvT"
      },
      "outputs": [],
      "source": [
        "# Provided dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Dataset\n",
        "data = {\n",
        "    'Hours Studied': [1.1, 2.5, 3.2, 5.5, 7.1, 8.3, 9.2, 10.5],\n",
        "    'Percentage Score': [10, 25, 30, 50, 65, 70, 85, 95]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agb4aedPOpvU"
      },
      "source": [
        "(a) Plot the data points using a scatter plot. The plot should contain a title, and labels for the x, y axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBi4Qr_qOpvU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scatter plot\n",
        "# TODO: Add your code here\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd-RNYDAOpvU"
      },
      "source": [
        "(b) Fit a linear regression model to the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZOgesdkOpvV"
      },
      "outputs": [],
      "source": [
        "# Task 2: Fitting a linear regression model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Prepare the data\n",
        "X = df[['Hours Studied']]\n",
        "y = df['Percentage Score']\n",
        "\n",
        "# Initialize the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# TODO: Fit the model\n",
        "# model.fit(...)\n",
        "\n",
        "# Print the model parameters\n",
        "print(f\"Intercept: {model.intercept_}\")\n",
        "print(f\"Coefficient: {model.coef_[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4fdAqb0OpvV"
      },
      "source": [
        "(c) Plot the regression line on the scatter plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNXJGi3HOpvV"
      },
      "outputs": [],
      "source": [
        "# Task 3: Plotting the regression line\n",
        "\n",
        "# Generate prediction line\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# TODO: Add your code here\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kcmZPrMOpvV"
      },
      "source": [
        "(d) Predict the percentage score for a student who studies for 6.5 hours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqA_B5IgOpvV"
      },
      "outputs": [],
      "source": [
        "# Task 4: Predicting the score\n",
        "# TODO: Predict the percentage score for 6.5 hours of study\n",
        "\n",
        "print(f'Predicted score for {hours} hours of study: {predicted_score[0]:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXfs_pD7OpvV"
      },
      "source": [
        "### Analysis Questions\n",
        "\n",
        "(e) **Model Parameters**: What do the intercept and coefficient tell you about the relationship between hours studied and percentage score?\n",
        "   - **[TODO: Fill your response here]**\n",
        "\n",
        "(f) **Prediction Accuracy**: How accurate do you think the prediction for 6.5 hours is? Justify your answer using the data.\n",
        "   - **[TODO: Fill your response here]**\n",
        "\n",
        "(g) **Model Fit**: Look at the scatter plot with the regression line. Does the line seem to fit the data well? Are there any outliers or patterns that the line does not capture?\n",
        "   - **[TODO: Fill your response here]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8-D8vDROpvV"
      },
      "source": [
        "## 6. Polynomial Regression: Analyzing Overfitting and Model Fit (15 pts, 5 pts each)\n",
        "\n",
        "In this exercise, you will visually analyze the effects of increasing the polynomial degree in regression modeling. By observing how the model fits the data and how the $R^2$ score varies, you'll gain insights into overfitting and determine an appropriate degree for polynomial regression.\n",
        "\n",
        "**Generate and Plot Synthetic Data**:\n",
        "- You'll use a synthetic dataset to clearly see the effects of model complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuMvcWhgOpvV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generating synthetic data\n",
        "np.random.seed(0)\n",
        "x = np.linspace(-3, 3, 100)\n",
        "y = 0.5 * x**3 - 2 * x**2 + x + np.random.randn(100) * 5\n",
        "\n",
        "# Visualizing the data\n",
        "plt.scatter(x, y)\n",
        "plt.title(\"Synthetic Cubic Data\")\n",
        "plt.xlabel(\"Feature (x)\")\n",
        "plt.ylabel(\"Target (y)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_fGZpdrOpvV"
      },
      "source": [
        "**Experiment with Polynomial Degrees**:\n",
        "- Experiment with different degrees and observe how the model's fit changes.\n",
        "- Plot all results on one graph and display the \\(R^2\\) score for each degree to assess model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZIuia_hOpvV"
      },
      "outputs": [],
      "source": [
        "# Set the maximum degree of polynomial to test\n",
        "max_degree = 10\n",
        "\n",
        "# Prepare plotting\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(x, y, color='grey', label='Data points')\n",
        "\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, max_degree))\n",
        "\n",
        "# Analyze polynomial degrees from 1 to max_degree\n",
        "r2_scores = []\n",
        "for degree in range(1, max_degree + 1):\n",
        "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "    model.fit(x[:, np.newaxis], y)\n",
        "    y_pred = model.predict(x[:, np.newaxis])\n",
        "    r2 = r2_score(y, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "    plt.plot(x, y_pred, color=colors[degree-1], label=f'Degree {degree} (R^2={r2:.2f})')\n",
        "\n",
        "# Plot settings\n",
        "plt.title(\"Polynomial Regression: Degree Effects\")\n",
        "plt.xlabel(\"Feature (x)\")\n",
        "plt.ylabel(\"Target (y)\")\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
        "plt.show()\n",
        "\n",
        "# Plot R^2 scores\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(range(1, max_degree + 1), r2_scores, marker='o')\n",
        "plt.title(\"R^2 Scores by Polynomial Degree\")\n",
        "plt.xlabel(\"Degree of Polynomial\")\n",
        "plt.ylabel(\"R^2 Score\")\n",
        "plt.xticks(range(1, max_degree + 1))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBkonF7LOpvV"
      },
      "source": [
        "### Analysis Questions:\n",
        "\n",
        "- (a) **Observe the Fit**: How does the fit change as the polynomial degree increases?\n",
        "- (b) **Optimal Degree**: Based on the \\(R^2\\) score and visual inspection, what seems to be the optimal degree for the polynomial?\n",
        "- (c) **Overfitting Signs**: At what degree do you start noticing overfitting? How can you tell?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C961FLwEOpvW"
      },
      "source": [
        "**[TODO: Fill your response here]**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Bonus Question: Implementing SGD for Linear Regression and Comparison with Scikit-Learn (5 bonus pts)\n",
        "\n",
        "Complete the missing lines of code to implement Stochastic Gradient Descent (SGD) for Linear Regression from scratch and compare the performance and results with Scikit-Learn's SGDRegressor.\n",
        "\n",
        "### Task Description\n",
        "- SGD Implementation: Fill in the missing lines of code to complete the basic version of SGD that fits a linear model to the synthetic data created previously. Initialize parameters randomly and update them using the gradient of the loss function computed from randomly sampled data points.\n",
        "Use Scikit-Learn's SGDRegressor:\n",
        "- Apply the SGDRegressor from Scikit-Learn to the same dataset using provided parameters.\n",
        "- Comparison: Compare the coefficients and intercepts from both models.\n",
        "Plot both models' predictions on the same graph to visually inspect the similarities or differences.\n",
        "\n",
        "### Implementation Guide\n",
        "\n",
        "(a) Fill in the `#TODO` lines to implement the SGD, plot the predictions and print the model parameters."
      ],
      "metadata": {
        "id": "WjmXb-hMREc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "# Generate some linear data\n",
        "np.random.seed(42)\n",
        "x = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * x + np.random.randn(100, 1)\n",
        "\n",
        "# Implementing simple SGD for Linear Regression\n",
        "class SimpleSGDRegressor:\n",
        "    def __init__(self, eta=0.01, n_iter=10000): # eta is the learning rate\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        # Random weight initialization\n",
        "        self.weights = np.random.randn(n_features + 1)\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            for i in range(n_samples):\n",
        "                index = np.random.randint(n_samples)\n",
        "                xi = np.insert(X[index], 0, 1)  # Adding bias term\n",
        "                yi = y[index]\n",
        "                # TODO: Calculate the gradient and update weights\n",
        "                # gradient = ...\n",
        "                # self.weights -= ...\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(np.c_[np.ones((len(X), 1)), X], self.weights)\n",
        "\n",
        "# Using Scikit-Learn's SGDRegressor\n",
        "sklearn_sgd = SGDRegressor(max_iter=1000, tol=1e-3, eta0=0.1, random_state=42)\n",
        "sklearn_sgd.fit(x, y.ravel())\n",
        "\n",
        "# Comparing implementations\n",
        "our_sgd = SimpleSGDRegressor()\n",
        "our_sgd.fit(x, y.ravel())\n",
        "\n",
        "# Plotting predictions\n",
        "plt.scatter(x, y, color='gray', label='Data')\n",
        "plt.plot(x, our_sgd.predict(x), color='red', label='Simple SGD')\n",
        "plt.plot(x, sklearn_sgd.predict(x), color='blue', linestyle='dashed', label='Scikit-Learn SGD')\n",
        "plt.title(\"Comparison of SGD Implementations\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print model parameters\n",
        "print(\"Our Simple SGD Coefficients:\", our_sgd.weights[1:], \"Intercept:\", our_sgd.weights[0])\n",
        "print(\"Scikit-Learn SGD Coefficients:\", sklearn_sgd.coef_, \"Intercept:\", sklearn_sgd.intercept_)"
      ],
      "metadata": {
        "id": "p-KsVEfITAz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Run the following code snippet. Compare the prediction accuracy of our simple SGD and the Scikit-learn SGD."
      ],
      "metadata": {
        "id": "VqUU-7baT0Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Calculate predictions\n",
        "predictions_our_sgd = our_sgd.predict(x)\n",
        "predictions_sklearn_sgd = sklearn_sgd.predict(x)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse_our_sgd = mean_squared_error(y, predictions_our_sgd)\n",
        "mse_sklearn_sgd = mean_squared_error(y, predictions_sklearn_sgd)\n",
        "\n",
        "# Calculate R^2 Score\n",
        "r2_our_sgd = r2_score(y, predictions_our_sgd)\n",
        "r2_sklearn_sgd = r2_score(y, predictions_sklearn_sgd)\n",
        "\n",
        "# Print the results\n",
        "print(\"Mean Squared Error (Our SGD):\", mse_our_sgd)\n",
        "print(\"Mean Squared Error (Scikit-Learn SGD):\", mse_sklearn_sgd)\n",
        "print(\"R^2 Score (Our SGD):\", r2_our_sgd)\n",
        "print(\"R^2 Score (Scikit-Learn SGD):\", r2_sklearn_sgd)"
      ],
      "metadata": {
        "id": "FVdW1Py8ZFTs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}